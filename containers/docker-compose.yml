# Docker Compose configuration for Pitchey Container Services
# Production-ready containerized services for video processing, document handling, AI inference, etc.

version: '3.8'

services:
  # Video Processing Container
  video-processor:
    build:
      context: ./video-processor
      dockerfile: Dockerfile
    container_name: pitchey-video-processor
    ports:
      - "8081:8080"
    environment:
      - PORT=8080
      - MAX_WORKERS=3
      - MAX_FILE_SIZE=500000000  # 500MB
      - DEBUG=false
      - JWT_SECRET=${JWT_SECRET:-default-secret}
      - API_KEY_DEFAULT=${API_KEY_DEFAULT:-video-processor-key}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379}
    volumes:
      - video_processing:/tmp/processing
      - video_uploads:/app/uploads
      - video_outputs:/app/outputs
    depends_on:
      - redis
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Document Processing Container
  document-processor:
    build:
      context: ./document-processor
      dockerfile: Dockerfile
    container_name: pitchey-document-processor
    ports:
      - "8082:8080"
    environment:
      - PORT=8080
      - MAX_WORKERS=3
      - MAX_FILE_SIZE=100000000  # 100MB
      - DEBUG=false
      - JWT_SECRET=${JWT_SECRET:-default-secret}
      - API_KEY_DEFAULT=${API_KEY_DEFAULT:-document-processor-key}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379}
    volumes:
      - document_processing:/tmp/processing
      - document_uploads:/app/uploads
      - document_outputs:/app/outputs
      - document_templates:/app/templates
    depends_on:
      - redis
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 1.5G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # AI Inference Container
  ai-inference:
    build:
      context: ./ai-inference
      dockerfile: Dockerfile
    container_name: pitchey-ai-inference
    ports:
      - "8083:8080"
    environment:
      - PORT=8080
      - MAX_WORKERS=2
      - DEBUG=false
      - JWT_SECRET=${JWT_SECRET:-default-secret}
      - API_KEY_DEFAULT=${API_KEY_DEFAULT:-ai-inference-key}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379}
      - HF_HOME=/app/.cache/huggingface
      - TRANSFORMERS_CACHE=/app/.cache/transformers
    volumes:
      - ai_models:/app/models
      - ai_cache:/app/.cache
      - ai_uploads:/app/uploads
    depends_on:
      - redis
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '3.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s  # AI models take longer to load

  # Media Transcoder Container
  media-transcoder:
    build:
      context: ./media-transcoder
      dockerfile: Dockerfile
    container_name: pitchey-media-transcoder
    ports:
      - "8084:8080"
      - "1935:1935"  # RTMP streaming port
    environment:
      - PORT=8080
      - MAX_WORKERS=2
      - MAX_FILE_SIZE=1000000000  # 1GB
      - DEBUG=false
      - JWT_SECRET=${JWT_SECRET:-default-secret}
      - API_KEY_DEFAULT=${API_KEY_DEFAULT:-media-transcoder-key}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379}
    volumes:
      - media_processing:/tmp/processing
      - media_uploads:/app/uploads
      - media_streams:/app/streams
      - media_manifests:/app/manifests
    depends_on:
      - redis
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2.5'
          memory: 3G
        reservations:
          cpus: '1.0'
          memory: 1G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Code Executor Container
  code-executor:
    build:
      context: ./code-executor
      dockerfile: Dockerfile
    container_name: pitchey-code-executor
    ports:
      - "8085:8080"
    environment:
      - PORT=8080
      - MAX_WORKERS=2
      - DEBUG=false
      - JWT_SECRET=${JWT_SECRET:-default-secret}
      - API_KEY_DEFAULT=${API_KEY_DEFAULT:-code-executor-key}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379}
    volumes:
      - code_sandbox:/tmp/sandbox
      - code_execution:/tmp/execution
      - code_uploads:/app/uploads
    depends_on:
      - redis
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    security_opt:
      - seccomp:unconfined  # Required for firejail sandboxing
    cap_add:
      - SYS_ADMIN  # Required for containerized sandboxing

  # Redis Cache (shared by all services)
  redis:
    image: redis:7-alpine
    container_name: pitchey-redis
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # Nginx Load Balancer and API Gateway
  nginx:
    image: nginx:alpine
    container_name: pitchey-gateway
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
      - nginx_cache:/var/cache/nginx
    depends_on:
      - video-processor
      - document-processor
      - ai-inference
      - media-transcoder
      - code-executor
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Monitoring and Metrics (Prometheus + Grafana)
  prometheus:
    image: prom/prometheus:latest
    container_name: pitchey-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M

  grafana:
    image: grafana/grafana:latest
    container_name: pitchey-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M

volumes:
  # Video processor volumes
  video_processing:
    driver: local
  video_uploads:
    driver: local
  video_outputs:
    driver: local

  # Document processor volumes
  document_processing:
    driver: local
  document_uploads:
    driver: local
  document_outputs:
    driver: local
  document_templates:
    driver: local

  # AI inference volumes
  ai_models:
    driver: local
  ai_cache:
    driver: local
  ai_uploads:
    driver: local

  # Media transcoder volumes
  media_processing:
    driver: local
  media_uploads:
    driver: local
  media_streams:
    driver: local
  media_manifests:
    driver: local

  # Code executor volumes
  code_sandbox:
    driver: local
  code_execution:
    driver: local
  code_uploads:
    driver: local

  # Shared volumes
  redis_data:
    driver: local
  nginx_cache:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

networks:
  default:
    name: pitchey-containers
    driver: bridge